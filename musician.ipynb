{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1S6IPeIHk8J_2AjfJJpsIDN2d_T6USd2V",
      "authorship_tag": "ABX9TyMDF9sIEmhYsY7vRiMKP24O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshVardhanKumar/Chart.js/blob/master/musician.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lThpBpXCkHMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from music21 import converter, instrument, note, chord\n",
        "import glob\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHPnOGMgvVph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Acknowledgment: This part of Code taken from https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
        "vocabulary = []\n",
        "i = 0\n",
        "for tunes in glob.glob(\"/content/drive/My Drive/music/*.mid\"):\n",
        "    midi = converter.parse(tunes)\n",
        "    notes = None\n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    if parts: \n",
        "        notes = parts.parts[0].recurse()\n",
        "    else: \n",
        "        notes = midi.flat.notes\n",
        "    for element in notes:\n",
        "        if isinstance(element, note.Note):\n",
        "            vocabulary.append(str(element.pitch))\n",
        "        elif isinstance(element, chord.Chord):\n",
        "            vocabulary.append('.'.join(str(n) for n in element.normalOrder))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s5Jl20OzAKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/notes', 'wb') as f:\n",
        "  pickle.dump(vocabulary, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gsfOLzXvo4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/notes', 'rb') as f:\n",
        "  vocabulary = pickle.load(f)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "seq_length = 250\n",
        "unique_notes = set(vocabulary)\n",
        "n_unique_notes = len(unique_notes)\n",
        "pitchnames = sorted(unique_notes)\n",
        "\n",
        "# Encoding the notes as integers\n",
        "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "for i in range(0, len(vocabulary) - seq_length, 1):\n",
        "        inputs.append([note_to_int[char] for char in vocabulary[i:i+seq_length]])\n",
        "        outputs.append(note_to_int[vocabulary[i+seq_length]])\n",
        "\n",
        "# the model has only single input for each sequence\n",
        "inputs = np.reshape(outputs, (len(inputs), seq_lengths,1))\n",
        "\n",
        "X_train = torch.from_numpy(np.asarray(inputs / float(n_unique_notes))).float()\n",
        "Y_train = torch.from_numpy(np.asarray(np_utils.to_categorical(outputs))).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI7kEgaq4RIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = DataLoader(TensorDataset(X_train, Y_train), batch_size = 32)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S5gMlFAvyhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the model\n",
        "class LSTM_Music(nn.Module):\n",
        "  def __init__(self, hidden_dim, vocab_size, input_size):\n",
        "    super(LSTM_Music, self).__init__()\n",
        "    #self.lstm = nn.LSTM(input_size = input_size, hidden_dim=hidden_dim, num_layers=2, dropout = 0.2, bidirectional=True)\n",
        "    self.lstm = nn.LSTM(input_size, hidden_dim, dropout=0.2, num_layers=2, bidirectional=True)\n",
        "    self.drop1 = nn.Dropout(p=0.2)\n",
        "    self.gru = nn.GRU(2*hidden_dim, hidden_size = hidden_dim)\n",
        "    self.drop2 = nn.Dropout(p=0.2)\n",
        "    self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "    self.out = nn.Softmax()\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x,_ = self.lstm(x)\n",
        "    x=self.drop1(x)\n",
        "    x,_ = self.gru(x)\n",
        "    x = self.fc(x)\n",
        "    x = self.out(x)\n",
        "    return x[:,x.shape[1]-1,:]\n",
        "\n",
        "hidden_dim = 500\n",
        "input_size = X_train.shape[2]\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device='cuda:0'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "model = LSTM_Music(input_size = input_size, hidden_dim = hidden_dim, vocab_size = n_unique_notes)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ity58l-M6bvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(lstm, dataloader, epochs=20):\n",
        "  loss_fn = nn.BCELoss()\n",
        "  min_cost = 99\n",
        "  optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
        "  loss_fn.to(device)\n",
        "  for e in range(epochs):\n",
        "    lv = 0.0\n",
        "    for input,output in dataloader:\n",
        "      model.zero_grad();\n",
        "      input = input.cuda()\n",
        "      predictions = model(input)\n",
        "\n",
        "      output = output.cuda()\n",
        "      loss = loss_fn(predictions, output)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      lv = lv+loss.item()\n",
        "    print(\"Epoch \"+str(e)+\" loss = \"+str(lv/len(dataloader)))\n",
        "    if lv/len(dataloader) < min_cost :\n",
        "      min_cost = lv/len(dataloader)\n",
        "      torch.save(model.state_dict(), '/content/drive/My Drive/musician.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZt8W1RK7oqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a1a39e97-d440-4f36-afb0-c58fcabe3747"
      },
      "source": [
        "train(model, trainloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 loss = 0.04019640274956888\n",
            "Epoch 1 loss = 0.040196401875253196\n",
            "Epoch 2 loss = 0.04019638523616912\n",
            "Epoch 3 loss = 0.040196381651348846\n",
            "Epoch 4 loss = 0.04019639753328059\n",
            "Epoch 5 loss = 0.040196388287140304\n",
            "Epoch 6 loss = 0.0401963929632804\n",
            "Epoch 7 loss = 0.04019638093734537\n",
            "Epoch 8 loss = 0.040196389633258896\n",
            "Epoch 9 loss = 0.04019638102836743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlYEUG3hiKL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/musician.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8igwAqkc7tP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}